# Intro

## What is the Mind of Apollo?
Mind of Apollo is an open-source, collaboratively edited website hosting a network of arguments.

The arguments are scored, but not by a popular vote, judges or AI. How then? First, I need to explain how the arguments are organized.
+ How are the arguments organized?
+ Who controls the tech?
+ Define "argument"
+ How is this different from Wikipedia?
+ How is this different from Kialo?
+ How is this different from a typical debate (platform/society)?
+ Define "score"


## How are the arguments organized?
<!-- Image: "Argument structure" https://docs.google.com/drawings/d/14DLTloX6NnbL3AkZ6NM_7BNMt1XoOCgL2E7SlpXkWeo/edit?usp=sharing -->
![Argument structure](/images/argument_structure.png)

Statement (S1) at the top is the main claim. It has a pro (A2) and a con (A1) arguments attached to it. These arguments rely on premises recorded as independent statements (S2, S3, S4). In turn, these statements have deeper arguments attached to them, and so on.
+ How does roll-up scoring work?
+ Define "statement"


## How does roll-up scoring work?
![Argument structure](/images/argument_structure.png)

The website calculates the likelihood that the claim is true based on the strengths of arguments that are attached to it. The strength of an argument is calculated based on the likelihoods of the premises that it relies on. So the scores are calculated automatically all the way up from the very bottom layer of premises. If there is a significant disagreement between the editors about the likelihood of a bottom-level premise, more arguments and premises are added below it until an agreement is reached.
+ What value does this project add?
+ How are the arguments organized?
+ Can I trust these calculations?
+ Which axioms lie at the bottom?
+ Define "likelihood"
+ Define "strength"
+ Define "score"
+ Define "premise"


## What value does this project add?
The cognitive resources unlocked by productive mass collaboration on this platform can be used to conduct conclusive investigations on questions that require pulling a lot of research and evidence together while avoiding mistakes in reasoning.
+ What is the goal of the project?
+ Will the combined reasoning be good?


## What is the goal of the project?
If Apollo becomes capable of consistently rational, open and well-informed judgement, then it will gain public trust as it consistently makes good predictions. Many disagreements could be resolved by deferring to Apollo, ultimately resulting in much better-decision making on a large scale.
+ What should I explore next?
+ Will the combined reasoning be good?


## What should I explore next?
Thank you for reading the introduction. Please continue exploring the about page to find further details, clarifications and answers.

If you find these ideas interesting start [exploring](/) and [editing](/join) the Mind of Apollo platform and join the conversation on our [Discord](https://discord.gg/3hhhD4tK9h).





# How is this different from ...?

## How is this different from Wikipedia?
Wikipedia is primarily a repository of knowledge. It lacks a built-in mechanism for systematic reasoning (eg. It has no scoring or argument graphing system).

As a result, for contentious matters it often presents a brief overview and some resources from multiple sides and then says nothing more about what's true.

The Mind of Apollo provides a mechanism for systematically reasoning about more contentious issues.


## How is this different from Kialo?
The primary function of Kialo is collecting arguments and letting readers form their independent opinions. It has a popular vote feature, but the voters are not even required to read any of the arguments to cast their vote, so it's of little significance.

In contrast, in the Mind of Apollo, the scores are derived automatically based on the whole argument structure below each claim. These scores are deeply justified, platform-wide conclusions rather than opinions of individual users that have questionable depth.
+ Why having a single score per claim / argument is important?


## How is this different from a typical debate (platform/society)?
Typical debate(r)s often struggle to keep track of all the important information. They have to contend with very limiting time constraints. Typical debates don't have many reasoners involved.
+ Advantage of roll-up scores
+ Advantage of canonically
+ Advantage in memory
+ Advantage in time available
+ Advantage in numbers


## Advantage of roll-up scores
In typical debates, unreliable intuitions must be relied on to calculate and combine confidences, giving our cognitive biases a huge opportunity to influence our thinking.

In Apollo, confidences are mathematically combined, leaving little room for such biases in score combination.


## Advantage of canonically
In typical debates and debate societies/platforms, past work is not often systematically saved and reused in future works, leading to lots of pointless repetition.

Apollo's statements are canonical, meaning it's intended that only one in-platform statement should exist for each concept trying to be described by that statement.

As such, if you (or anyone else) searches for a statement that you/they intend to make and it has already been made, it can be found and linked (along with indirectly all of its descendent entries) without any necessary repetition.


## Advantage in memory
In vocal debates, remembering all the important statements and arguments can quickly become quite difficult. This can easily result in unrecognized contradictions or conflations.

In text (and thus also in Apollo), all statements and arguments are saved and you can look back over them whenever you like.

An added bonus of Apollo is that the statements/arguments tend to be somewhat organized and sometimes tagged, making them quicker and easier to find in general.


## Advantage in time available
In Apollo, anyone with the free time can take as long as they want (and as many days as they want) to iron out all the important details they can think of.

Typical debates, whether between an informal group of people, or formally presented and moderated, are usually too short and rarely properly revisited. As such, there is typically far less than the required amount of work done to cover all the relevant and important points, to the final important level of detail.

It's typically harder to dive deep into a single point without seeming to change the subject in a counterproductive way, since there is so little time to cover everything.

There is generally insufficient time to thoroughly investigate sources during a vocal debate. Thus important sources are often left unused or unscrutinised.


## Advantage in numbers
Typical debates are 1v1 or sometimes small group vs small group, meaning there are often important nuances that are missed as a result of the limited knowledge/calculation of the participants (even if they are experts in the relevant subject(s)).

Mind of Apollo is open to almost everyone, meaning that the amount of available knowledge and human cognition the platform can potentially draw on for more important topics is much greater.





# Why is it useful?

## What value does this project add?
<!-- The contents of this section were added earlier. This header is here to add a the link to the section to this group. -->


## What is the goal of the project?


## Doesn't everyone have their own truth?
In the context of this project, the word "truth" refers to objective truth. It corresponds to the way things actually are in the world. Objective truth is independent of anyone's beliefs, opinions or feelings.

But does objective truth exist?

**Argument from objective reality** - If you believe that there is an external world that we all inhabit and share, then there are necessarily facts about the world which are also objective, therefore at least those objective truths exist.

**Argument from site axioms** - If you accept that platform's descriptive axioms objectively apply in all cases regardless of anything else, then (assuming that involves identity, contradiction, modus ponens and the semi-reliability of your own mental faculties) you must surely accept that at least those objective truths exist.
+ Which descriptive axioms are supported?


## Why not leave this to science and other authorities?
Current scientific (and other) institutions have a hard time properly aggregating the results of their many conjectures, theories, experiments and proofs, particularly for many important and controversial issues.

Mind of Apollo could become a great, often-used format for general, complex reasoning. I'm not aware of better alternatives that could become commonly used. If you have any suggestions for this, please [join the discord](https://discord.gg/x23ycnckHN) and share.


## Wouldn't controversial conclusions be ignored by most people who disagree?
If successful, Apollo would be able to consistently make great predictions in many very different testable areas, making it more difficult for people to deny its general reasoning prowess.

If Apollo is successful and the topic is known to be important, those who disagree for bad reasons would often attempt to counterargue Apollo, and in doing so have all their arguments addressed very clearly and thoroughly.

In cases where only 50-80% of people wouldn't change their minds, 20-50% of people still means a very large amount of changed minds for many topics, and would still help a lot.

For topics where 80-100% of people wouldn't change their minds, future generations still could, especially if Apollo convinces enough people to promote things like educational reforms establishing in-depth curriculums for general reasoning.
+ Why do you think a group of random people on the internet will be particularly smart?
+ How would people recognize its ability to make consistent predictions?
+ Will the arguments be effective?


## Conflict is natural, why fight it?
This project is not an attempt to eliminate conflict. Its goal is to change how it is conducted.

My hope is just to make tactics such as emotional manipulation ineffective, make an environment where disagreement between its editors can more frequently be a productive activity, generate knowledge and a deeper understanding of the issues, help to reveal which solutions are truly best, clarify what is at stake for all parties, etc.

There is a chance that such an environment can even serve as a fair and satisfying arena for settling disputes with reason before they escalate into violence.





# Is it satisfying?

## Deep and meaningful interactions
The experience of seeing thoughtful, rational responses to what you write, and feel heard and understood.

The experience of engaging with reasonable people who value truth, critical thinking, and intellectual honesty.

Freedom of speech (mostly)
+ What content is allowed?


## Getting closer to truth
If Apollo functions as intended, it can help by allowing users to more systematically and collaboratively think through practically anything.
+ Will the combined reasoning be good?


## Debating as a sport
Users can engage in the challenge of trying to convince Apollo of their reasoning better than others can.

In the near future there will likely be a rating system (like chess elo) to measure skill at convincing Apollo of claims.


## Convincing others
The Mind of Apollo can be used for persuasion. Coming up with strong arguments and dismantling weak ones will affect the platform's conclusions. This shift together with the arguments themselves will affect other people's opinions.
+ How does roll-up scoring work?
+ Will the combined reasoning be good?
+ Wouldn't controversial conclusions be ignored by most people who disagree?
+ Will the arguments be effective?


## Becoming more reasonable
The Mind of Apollo is a place to test and refine your reasoning and ideas.
+ Will there be learning materials?
+ What are the editing guidelines?


## Part of a collective brain
The Mind of Apollo together with its editors maintain a single coherent, growing and self-correcting belief system. Together they can be thought of as one collective reasoner. By becoming one of its first contributors, you can watch and guide its growth into something the could gain superhuman reach and insight.
+ Define "belief system"





# Could it be harmful?

## Isn't it dangerous to create such an authority?
Like with any innovation, there is a potential for it to go wrong. Too many people may start trusting the Apollo too much.

Before it becomes quite popular/effective, it would most likely not be particularly dangerous, since most people would remain sceptical that it's really so reliable. But once it becomes quite popular/effective, it could become very dangerous.

If it's still quite reasonable despite many people's overzealous devotion, the overestimation would likely not be very costly in most cases.

Otherwise, this could be a big problem. We are of course attempting to design it such that this doesn't become a big issue, but there's always a chance that we will fail.
+ How prevent overconfidence in conclusions?
+ Who controls the tech?
+ Who controls the scoring?


## How prevent overconfidence in conclusions?
Blemishes in Apollo's track record may greatly reduce the number of people who trust it blindly. To that end, we intend to create a system to keep account of the failed predictions and keep them visible.

If Apollo becomes successful, perhaps in the future there should be an independent monitoring organisation overlooking it and similar platforms and raising the alarm if any start showing signs of corruption and/or making bad predictions.


## Won't rationality do more harm than good?
(TODO) enlightenment & modernism VS postmodernism





# Quality of combined reasoning

## How does roll-up scoring work?


## Can I trust these calculations?
The algorithm that derives scores is currently not very sophisticated and likely to result in issues like double-counting. In the future this will likely be refined, or if not, I will likely switch to a user-based scoring system that guides users to largely follow the algorithm in most cases.

At the moment the strength of an argument is determined simply by multiplying the likelihoods of its premises. You can get some intuition for how the argument scores are rolled up into statement scores by using [confidence calculator](https://mindofapollo.org/confidence-calculator).

For more details you can join [the discord](https://discord.gg/x23ycnckHN) or check out the [formulas in the source code](https://github.com/vdzk/mindofapollo/tree/main/src/calc).


## Will the combined reasoning be good?
Mind of Apollo platform as a whole would plausibly greatly help with reasonable decision-making on many important topics. It will plausibly become consistently rational, open and well-informed.

Irrationality can almost always be boiled down to an inconsistent application of a manageable set of reasoning principles. This site will guide and enforce the consistent application of those reasoning principles.
+ What are the editing guidelines?
+ Will there be learning materials?
+ Why do you think a group of random people on the internet will be particularly smart?
+ How accurate are the platform's conclusions?


## Why do you think a group of random people on the internet will be particularly smart?
I don't. However when guided and forced to follow good reasoning principles with scores of parent entries being derived automatically, a common set of descriptive axioms and a good definition system, I believe irrationality will (once everything is refined) likely have a much harder time finding sufficient gaps to heavily corrupt Apollo's reasoning.

And as for pure depth/breadth of reasoning, I believe Apollo's collaboratively edited system and clear, relatively simple criteria will make for well-defined tasks that (again once sufficiently refined) allow many people (even when relatively uncritical or ignorant) to contribute in such a way that the aggregated process can produce a very good result.
+ How does roll-up scoring work?
+ Will the combined reasoning be good?


## Why having a single score per claim / argument is important?
The fact that a claim has a single score at any point in time, rather than per user, creates a strong point of contention. This in turn will motivate many editors to move this score in their direction. This requires finding flaws in the arguments of their opponents and strengthening the argument on their side. The Mind of Apollo platform provides guidance on how to do it in line with critical thinking standards and enforces those standards.

This continuous refinement of arguments will improve their persuasiveness and the accuracy of the platform's conclusions.
+ What are the editing guidelines?


## Will there be learning materials?
There will likely be learning materials to teach people the basics of reasoning, particularly as it relates to Apollo's systems and how to use them.


## How accurate are the platform's conclusions?
At this early stage, all of Apollo's conclusions are tentative. As the project matures, Apollo's reasoning process will become more robust and its knowledge of certain topics more comprehensive.

In the future, Apollo's scores will likely account for missing information (eg. unrepresented prior probabilities) in a better way, allowing the scores to better reflect how tentative/uncertain many entries are. For now, the scores of statements (and thus also, indirectly, arguments) are likely to be very overconfident (in both directions, towards 0% and 100%).
+ Will the combined reasoning be good?


## What are the editing guidelines?
Please open any of the arguments on the [platform](https://mindofapollo.org/) and explore its "How To" section as it describes proper ways to attack or defend an argument and influence its score. Depending on the argument type, you may get a combination of the general instructions and the argument type's specific instructions.


## How will the editing guidelines be enforced?
If the amount of very obviously unreasonable contributions doesn't put much of a strain on the more reasonable contributors, then we will likely avoid enforcing the criteria much to ensure we don't mistakenly silence useful voices.

But if there is a heavy strain and the platform cannot properly function without such enforcement, users who consistently add obviously unreasonable entries without contributing much else would likely have some permissions revoked (probably temporarily).

"Obviously unreasonable" here refers to things like arguments with clear, unambiguous logical contradictions with no good excuse, which the majority of users on the platform could easily point out. It typically does NOT refer to things like very unintuitive and against-common-sense arguments, such as many flat earth arguments. There has to be a very solid, immediate and obvious problem with enough contributions to revoke permissions. "Unreasonable" contributions which we can only call such because of our intuition must not be used as sufficient evidence to revoke permissions.


## How will the guidelines be evaluated?
I would imagine that good guidelines would be grounded in logic, probability theory, epistemology and informal logic.

Experimental psychology could shed light on how to minimise the effect of cognitive biases when an editor applies a guideline. 

We can observe which guidelines tend to result in more accurate predictions than others, collect examples where a guideline went wrong, etc. This could be a constant process of peer-reviewed research. Researchers could run experiments comparing how different guidelines lead to different problems.





# Persuasion

## Wouldn't controversial conclusions be ignored by most people who disagree?
If successful, Apollo would be able to consistently make great predictions in many very different testable areas, making it more difficult for people to deny its general reasoning prowess.

If Apollo is successful and the topic is known to be important, those who disagree for bad reasons would often attempt to counterargue Apollo, and in doing so have all their arguments addressed very clearly and thoroughly.

In cases where only 50-80% of people wouldn't change their minds, 20-50% of people still means a very large amount of changed minds for many topics, and would still help a lot.

For topics where 80-100% of people wouldn't change their minds, future generations still could, especially if Apollo convinces enough people to promote things like educational reforms establishing in-depth curriculums for general reasoning.
+ Why do you think a group of random people on the internet will be particularly smart?
+ How would people recognize its ability to make consistent predictions?
+ Will the arguments be effective?


## Will the arguments be effective?
Why would people change their mind when Apollo counterargues very well?

In typical argumentation, when a close-minded person is out of their previously learned arguments, they often begin subtly repeating already-addressed arguments or throwing whatever new arguments they can think of to defend their position. But unlike in a typical setting, Apollo would save the arguments they already gave and the counters they already received, so they wouldn't be able to repeat them. And Apollo could address all the new arguments they give, and many of these arguments would follow common flawed reasoning patterns, allowing many counterarguments to be efficiently reused in such cases.

In other words, Apollo could trounce such arguments so much more thoroughly and clearly than is otherwise possible, that for some, biases would not be enough to save their mind from changing.

If Apollo's reasoning is open, easy to follow and navigate, persuasive and covers the person's initial and subsequent objections, they will typically be much more likely to change their mind.
+ Can biases be really overcome?


## Can biases be really overcome?
Biases don't typically shut down the ability to comprehend opposing arguments completely. They compel people latch on to flaws and dismiss lines of thinking earlier than they should and give a pass to the flaws on their own side. But far less flaws in justifications (both in presentation and reasoning) means far less escape hatches for the biases to exploit.

If you take an honest biased person, they are not going to say to themselves "I dismiss this because I'm biased". They are compelled to find a rationalisation for it.

If the justification pre-empts and counters this rationalisation and it's done in a non-threatening way, then the person will often start changing their mind.

That's quite a high bar for a justification given the complexity of the issues and having to deal with uncertainty. I believe that is a big reason why we don't see people getting convinced by each other much.

I think it's a lot less threatening to read a justification for a view that you oppose in your own time. And do this while knowing that it resulted from a collaborative workflow that is open, involves people on all sides and has an explicit goal of being rational and self-correcting at the forefront.

So after a few encounters with Apollo addressing all one's objections, it seems plausible that they would recognize Apollo's epistemic authority and trust more of its future conclusions by default.


## Will the descriptive axioms be accepted?
People who understand the descriptive axioms shouldn't normally disagree with most of them. Even so, there will likely be a descriptive axiom selection system at some point so that different sets of descriptive axioms and their different conclusions can be accounted for.

Descriptive claims that are heavily dependent on particular axioms would likely not make up the majority of controversial claims.
+ Define "descriptive"


## Will the prescriptive axioms be accepted?
The current prescriptive axiom system allows individual users to select different prescriptive axioms and see different results that can be derived from them. So such disagreements would occur but would often be accounted for and understood to be based on differing axioms.

In many cases differences in prescriptive axioms will not change the ultimate conclusion. This could be because the differences are no big enough or because the proposed policy caters to multiple sets of preferences.
+ Define "prescriptive"


## What about dishonesty due to peer pressure?
What about dishonest people who just act like they disagree with Apollo to fit in?

If/when Apollo has not convinced many people around them, there's likely not much that can be done in such cases. But if/when Apollo convinces the people around them, it seems likely that they would act like they agree with Apollo even if they disagree, if they are dishonest for the sake of fitting in.


## What about dishonesty due to uncommon values?
There's likely little that can directly be done about such people. If people have uncommon values (e.g. private interests), then they may act like Apollo is untrustworthy despite believing otherwise, because good reasoning on other peoples' values would lead to less value for them.

For example an employee or share-owner of a business that damages the environment could be dishonest about their opinion on the damage, in order to reduce the risk to their personal finances and reputation.


## How would people recognize its ability to make consistent predictions?
There's a huge incentive for all kinds of news organizations, journalists, media outlets, etc. to tell the world about this mysterious oracle capable of predicting what traditional institutions cannot. Likewise there is a huge incentive for passionate users (and developers) to spread the word about this to such groups.

As such, if the predictions really are numerous, impressive and news-worthy, it should be a safe bet that many people will be made aware. And as more people join, it will be able to make more such predictions, plausibly leading to greater and greater growth and awareness.





# Abuse & moderation

## What will be done to prevent abuse?
Solid, unambiguous criteria so that bad but rule-following contributions can usually be easily and swiftly resolved.

A solid dispute resolution process so that when things cannot be easily or swiftly resolved, the system doesn't just continue operating based on the new scores but shows its internal conflict not being resolved normally.

Frequent/systematic backups and a history system to make it easy to fix things and see what caused them to break.


## What content is allowed?
#### Compliance with the law
The platform must not host illegal content, or it cannot reliably stay up. This includes messages that “incite a violation of the law that is both imminent and likely.”

#### Respectful communication
Criticism and commentary on others' contributions are absolutely allowed (and often encouraged), but should be expressed politely if possible. Rude or hostile behaviour tends to discourage participation by undermining the collaborative spirit the project aims to foster, which makes it difficult to have a larger positive impact.

#### Maintaining a positive public face
Like any public platform, Apollo has a public face that shapes first impressions. Since its growth depends heavily on public perception, it should present itself thoughtfully. Statements that most people would consider highly offensive should not be placed in prominent, public-facing areas (for example, on the homepage) unless there is a strong reason to do so. Such content should (assuming it is legal and not something like a personal attack with no plausible value) still remain accessible to those specifically seeking it, but it shouldn't confront people who didn't ask for it.
+ Does this platform have censorship?


## Does this platform have censorship?
Technically, but not strict censorship. For example the following would typically be allowed (though not necessarily endorsed):

NSFW topics - So long as details are kept vague. Keep in mind that children and adolescents may use this site, and there are not yet mechanisms in place for flagging/filtering sensitive content.

Conspiracy theories - Though users who consistently fail to follow the criteria may be subject to having scoring permissions revoked.
+ What content is allowed?


## How can we prevent moderator abuse?
Editors can report moderators on our [Discord](https://discord.gg/3hhhD4tK9h), citing the specific transgressions. For the time being, I will read reports and decide if those actions need to be undone and if those moderators need to be reprimanded. This system will improve as we encounter problems with it.


## Will the power to edit guidelines be abused?
The guidelines tend to be very low-level and applicable to many arguments. So it would typically be very difficult to predict how a change in a guideline would affect all the important conclusions in Apollo.

The process (and guidelines) will heavily encourage and guide the council members towards good reasoning, making it much more difficult for biases to slip in or for purposeful abuse to go unnoticed, especially if/when the depth and breadth of the reasoning becomes so significant that the only scores left to assign are pretty unambiguous and obvious.
+ Who controls the editing guidelines?


## How to report problems and make suggestions?
Please direct them to our [Discord](https://discord.gg/3hhhD4tK9h).





# Who controls this platform?

## Who controls the tech?
The code is open-source and freely available on [GitHub](https://github.com/vdzk/mindofapollo) together with instructions on starting your own server. So, if there will be a group of people who are dissatisfied with the current leadership they can branch off easily.
+ Who controls the content?


## Who controls the content?
Entries are not owned by anyone, similar to how no one owns a Wikipedia article. Generally every editor can edit any entry. Practically anyone is free to be an editor, so long as they make an account and follow the rules. Some additional restrictions apply to recently created accounts.

As with the code, the live database dumps are also freely available and can be used to kick-start a separate branch.
+ Who controls the scoring?
+ Define "entry"


## Who controls the scoring?
The scoring is determined by the argument structure below a claim, manually assigned scores for the very bottom level of premises and the roll-up algorithm that computes derived scores bottom-up.  
+ How does roll-up scoring work?
+ Will the combined reasoning be good?
+ Who controls the tech?
+ Who controls the content?
+ Who controls the editing guidelines?


## Who controls the editing guidelines?
The process of discussing changes to the rules/criteria will be open to everyone. My current tentative plan is to create a section of Apollo for deciding the guidelines, in which everyone can add entries, but only council members can score them.

For the time being I would be the only member of that council. After a userbase starts to establish itself, interested and trusted users may be selected for this.

Eventually the hope is to have professional philosophers, statisticians, cognitive scientists, etc. that can help make the final judgement, but we're a long way off from that.
+ What are the editing guidelines?
+ How will the guidelines be evaluated?
+ Will the power to edit guidelines be abused?


## How will this be funded?
It will be funded from donations, similar to Wikipedia.


## Who is leading this?
Hi! My name is Dante. I am a software dev with a Maths & Computer Science degree, living in the UK. I am a philosophy enthusiast who spent a year full time exploring these concepts as well as several years iterating on them in my spare time.
+ What are their motivations?


## What are their motivations?
I want the horrible things that are going on in the world to stop.

I want to be able to work full time on a meaningful, innovative and creative project like this.

I'm excited to use my programming, philosophical and critical thinking skills.





# Axioms

## Which axioms lie at the bottom?
Currently, the site supports different users adopting different prescriptive axioms but not different descriptive ones.
+ Which descriptive axioms are supported?
+ Which prescriptive axioms are supported?
+ Define "axiom"
+ Define "descriptive"
+ Define "prescriptive"


## Which descriptive axioms are supported?
+ The law of identity
+ The law of contradiction
+ Modus ponens works
+ The straight rule
+ The semi-reliability of the site's reasoning.


## The law of identity
All well-defined things/propositions are equal to themselves. All reasoning relies on propositions being equal to themselves, otherwise they could be different from themselves at virtually any point, resulting in absurdity.


## The law of contradiction
No well-defined proposition can be both true and false. If the law of contradiction is rejected, practically anything can be proven using [the principle of explosion](https://en.wikipedia.org/wiki/Principle_of_explosion).


## Modus ponens works
If (if x then y) and x, then y.
Without presupposing modus ponens (or anything similar), it seems we are unable to engage in logical inference. Because if only the other axioms listed here are presupposed, then it seems like we are unable to justify modus ponens.


## The straight rule
If m out of n observed instances of a type A have been found to be B, then the probability that the next A will be a B is m/n.

Without presupposing something like this, it seems at the very least quite difficult to justify inductive inference. Approaches have been suggested and will be investigated, but for the time being we will act as though this is another axiom for the sake of a relatively solid axiom set.


## The semi-reliability of the site's reasoning.
i.e. The assumption that the site has the bare minimum requirements to reason consistently enough.

If this is denied, anything can be contested on the grounds that "the site's reasoning is unreliable", and any counterargument would implicitly be based on the assumption that the site is capable of semi-reliably performing at least the most basic operations (for such a counterargument to be remotely reliable). Thus, just as it is necessary (for general reasoning) for people to presuppose the semi-reliability of their own mental faculties (to avoid never trusting themselves because of believing their own minds are unreliable), it is also necessary for the scoring system to reflect a site-wide axiom that the site is at least capable of the bare minimum.


## Which prescriptive axioms are supported?
Users may create/select prescriptive "goods" (eg. well-being), and prescriptive "weight profiles" with different weights for the "goods".

Amounts of these values can then be tied to entries, which are then calculated using the selected moral profile to show the final prescriptive value of a given action.

This is meant to provide a relatively objective way to analyze prescriptive claims without forcing users to accept a particular value paradigm.

I plan to expand this system to (at the very least) be more intuitive for those who hold non-consequentialist views. But for the time being it seems possible to reduce other views to weight profiles by eg. placing no weight on consequentialist metrics, and some regard for eg. rule-based metrics.





# Definitions

## Define "argument"
Some reasoning about fact(s) which supports a conclusion. Arguments are intended to either support (pro) or contest (con) the confidence of their parent statement. All arguments are made up of premises, which are statements.


## Define "axiom"
Epistemically unjustified assumption, common or uncommon.


## Define "belief system"
Belief - a statement or assumption that an individual accepts as true. It can describe facts about the world, interpretations of evidence, or general principles about how things work.

Belief system - the organized set of such beliefs that together form a person's understanding of reality. It includes not only what they believe but also how those beliefs support and relate to one another, creating a structured and coherent picture of the world.


## Define "confidence"
Same as likelihood.
+ Define "likelihood"


## Define "descriptive"
These statements describe how things are. They can be true or false, but they are not about what should be - only what is (or was, or will be).


## Define "entry"
An argument, statement, definition etc. that an editor added to the website.


## Define "likelihood"
(in this context of the website) means "credence given the available data".

Example: A flipping coin will typically objectively be (near) determined by the laws of physics to land on one side (thus the objective probability will typically be at least close to 100% or 0%). But given our inability to accurately predict the physical interactions involved, our credence for it landing on one side would (and should) still ordinarily be near (or at) 50%.


## Define "premise"
When supporting an argument, a statement is called a "premise" but functions almost exactly the same.
+ Define "statement"


## Define "prescriptive"
Statements about what someone should or should not do.


## Define "score"
The likelihood that a statement is true or the strength of an argument.
(likelihoods and strengths)
+ Define "likelihood"
+ Define "strength"


## Define "statement"
A claim about what is true/false.


## Define "strength"
Strength of an argument is the degree to which it changes the confidence in its conclusion.
+ Define "confidence"





# Miscellaneous

## Why the name "Apollo"?
The name was inspired by its philosophical meaning as a symbol of reason, clarity, harmony and self-knowledge. In philosophy, Apollo represents the rational and ordered aspect of human nature, and the pursuit of understanding through structure and truth.


## How are other languages handled?
All content on the platform is automatically translated into all the popular languages. This is to avoid some language-/culture-based biases and increase the amount of people who can participate.

This feature could also result in misleading or just plain wrong translations in many cases. Translated text may be marked as such and corrected manually. Though, we would have to be careful about this to prevent lots of user work being invested into translating content that may undergo significant edits which would render much of the translated text as unusable. 

Automatic translation could be limited or not used for content somehow marked (perhaps with tags or similar) as academic and/or containing sophisticated terminology (or perhaps just "shouldn't be auto-translated").

I think it's fair to say that English is the dominant language for academia, so the default may be blocking auto-translations from other languages into English in those cases. I would likely keep translating from English to other languages.
